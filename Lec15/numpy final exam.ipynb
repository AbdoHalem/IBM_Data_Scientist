{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Normalization\n",
    "\n",
    "In machine learning we use large amounts of data to train our models. Some machine learning algorithms may require that the data is *normalized* in order to work correctly. The idea of normalization, also known as *feature scaling*, is to ensure that all the data is on a similar scale, *i.e.* that all the data takes on a similar range of values. For example, we might have a dataset that has values between 0 and 5,000. By normalizing the data we can make the range of values be between 0 and 1.\n",
    "\n",
    "In this lab, you will be performing a different kind of feature scaling known as *mean normalization*. Mean normalization will scale the data, but instead of making the values be between 0 and 1, it will distribute the values evenly in some small interval around zero. For example, if we have a dataset that has values between 0 and 5,000, after mean normalization the range of values will be distributed in some small range around 0, for example between -3 to 3. Because the range of values are distributed evenly around zero, this guarantees that the average (mean) of all elements will be zero. Therefore, when you perform *mean normalization* your data will not only be scaled but it will also have an average of zero. \n",
    "\n",
    "# To Do:\n",
    "\n",
    "You will start by importing NumPy and creating a rank 2 ndarray of random integers between 0 and 5,000 (inclusive) with 1000 rows and 20 columns. This array will simulate a dataset with a wide range of values. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3768, 1269, 2399, ..., 1990, 2355, 4536],\n",
       "       [ 155, 1868, 4260, ..., 3343, 3233, 1947],\n",
       "       [4235, 2532,  815, ..., 1908, 1148,  516],\n",
       "       ..., \n",
       "       [2840, 3620, 3174, ..., 2803, 4638, 1027],\n",
       "       [1855,  249, 2369, ..., 4091, 3574, 2470],\n",
       "       [2532, 4666, 1081, ..., 4069, 1820, 2777]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import NumPy into Python\n",
    "import numpy as np\n",
    "\n",
    "# Create a 1000 x 20 ndarray with random integers in the half-open interval [0, 5001).\n",
    "X = np.random.randint(0,5001, size=(1000,20))\n",
    "\n",
    "# print the shape of X\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you created the array we will mean normalize it. We will perform mean normalization using the following equation:\n",
    "\n",
    "$\\mbox{Norm_Col}_i = \\frac{\\mbox{Col}_i - \\mu_i}{\\sigma_i}$\n",
    "\n",
    "where $\\mbox{Col}_i$ is the $i$th column of $X$, $\\mu_i$ is average of the values in the $i$th column of $X$, and $\\sigma_i$ is the standard deviation of the values in the $i$th column of $X$. In other words, mean normalization is performed by subtracting from each column of $X$ the average of its values, and then by dividing by the standard deviation of its values. In the space below, you will first calculate the average and standard deviation of each column of $X$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average of the values in each column of X\n",
    "avg_cols = X.mean(axis=0)\n",
    "\n",
    "# Standard Deviation of the values in each column of X\n",
    "std_cols = X.std(axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have done the above calculations correctly, then `ave_cols` and `std_cols`, should both be vectors with shape `(20,)` since $X$ has 20 columns. You can verify this by filling the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_cols =  [ 2463.187  2488.628  2567.766  2566.138  2449.787  2480.375  2441.622\n",
      "  2590.136  2534.93   2452.572  2439.86   2449.424  2477.595  2467.665\n",
      "  2458.217  2517.635  2458.386  2525.268  2470.694  2432.985]\n",
      "std_cols =  [ 1474.97500929  1449.4562317   1459.49297951  1438.31178573  1449.42472093\n",
      "  1418.40223363  1469.91658305  1432.88998165  1452.64695887  1394.92421472\n",
      "  1462.24494815  1443.65869104  1448.2996986   1445.41273025  1431.33065569\n",
      "  1464.6545353   1445.25073569  1440.6569863   1459.66935858  1457.70119598]\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of avg_cols\n",
    "print(\"avg_cols = \", avg_cols)\n",
    "\n",
    "# Print the shape of std_cols\n",
    "print(\"std_cols = \", std_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now take advantage of Broadcasting to calculate the mean normalized version of $X$ in just one line of code using the equation above. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean normalize X\n",
    "X_norm = (X - avg_cols) / std_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have performed the mean normalization correctly, then the average of all the elements in $X_{\\tiny{\\mbox{norm}}}$ should be close to zero, and they should be evenly distributed in some small interval around zero. You can verify this by filing the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average of all the values of X_norm =  4.26325641456e-18\n",
      "The average of the minimum value in each column of X_norm =  [-1.66659569 -1.71417939 -1.75661414 -1.78343668 -1.68396948 -1.74800557\n",
      " -1.65902067 -1.80134974 -1.74297684 -1.75462722 -1.66651969 -1.69459999\n",
      " -1.70654941 -1.70585532 -1.71533879 -1.71824477 -1.70101003 -1.75285861\n",
      " -1.69058423 -1.66837004]\n",
      "The average of the maximum value in each column of X_norm =  [ 1.71922438  1.73056071  1.65895556  1.68799423  1.75808579  1.77285747\n",
      "  1.7364101   1.6727481   1.69213172  1.81689297  1.74877677  1.76189567\n",
      "  1.740251    1.75198056  1.77022898  1.69348125  1.75236998  1.71778017\n",
      "  1.7170368   1.75277005]\n"
     ]
    }
   ],
   "source": [
    "# Print the average of all the values of X_norm\n",
    "print(\"The average of all the values of X_norm = \", X_norm.mean())\n",
    "\n",
    "# Print the average of the minimum value in each column of X_norm\n",
    "print(\"The average of the minimum value in each column of X_norm = \", X_norm.min(axis = 0))\n",
    "\n",
    "# Print the average of the maximum value in each column of X_norm\n",
    "print(\"The average of the maximum value in each column of X_norm = \", X_norm.max(axis = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should note that since $X$ was created using random integers, the above values will vary. \n",
    "\n",
    "# Data Separation\n",
    "\n",
    "After the data has been mean normalized, it is customary in machine learnig to split our dataset into three sets:\n",
    "\n",
    "1. A Training Set\n",
    "2. A Cross Validation Set\n",
    "3. A Test Set\n",
    "\n",
    "The dataset is usually divided such that the Training Set contains 60% of the data, the Cross Validation Set contains 20% of the data, and the Test Set contains 20% of the data. \n",
    "\n",
    "In this part of the lab you will separate `X_norm` into a Training Set, Cross Validation Set, and a Test Set. Each data set will contain rows of `X_norm` chosen at random, making sure that we don't pick the same row twice. This will guarantee that all the rows of `X_norm` are chosen and randomly distributed among the three new sets.\n",
    "\n",
    "You will start by creating a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`. You can do this by using the `np.random.permutation()` function. The `np.random.permutation(N)` function creates a random permutation of integers from 0 to `N - 1`. Let's see an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 3, 4, 2, 1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We create a random permutation of integers 0 to 4\n",
    "import numpy as np\n",
    "np.random.permutation(5)#like arange but not in order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Do\n",
    "\n",
    "In the space below create a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`. You can do this in one line of code by extracting the number of rows of `X_norm` using the `shape` attribute and then passing it to the  `np.random.permutation()` function. Remember the `shape` attribute returns a tuple with two numbers in the form `(rows,columns)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([781, 722, 955, 528, 208, 489, 696, 770, 398, 516, 234, 331, 279,\n",
       "       525, 498,  61, 334, 571, 462, 653,  97, 338, 908, 126, 877, 649,\n",
       "       796,   6, 150, 771, 669, 113, 788, 412, 259, 972, 577, 521, 911,\n",
       "       224, 664, 302, 996, 975,  59, 585, 735, 278,  13,  76, 795, 684,\n",
       "       934, 321, 260, 100,  55, 905, 166, 914, 834, 832, 775, 640, 612,\n",
       "       348, 590, 962, 988, 613, 974, 712, 843, 157, 423, 526, 200, 408,\n",
       "       557, 246, 617, 159, 852, 961, 921, 555, 822,   3, 333, 699, 448,\n",
       "       130, 574, 439, 813, 441, 847, 930, 232, 112, 950, 790, 139, 197,\n",
       "       756, 661, 938, 888, 297, 121, 430, 556, 592, 456, 135, 935, 369,\n",
       "       530, 876, 825, 779, 457,  89, 226, 437, 761, 816,   2, 724, 561,\n",
       "       158, 642, 951, 591, 774, 814, 303, 708, 881, 229, 210, 615, 466,\n",
       "       225, 491, 288, 872, 309, 710, 389,  33, 869, 184, 110, 152, 454,\n",
       "       968, 461, 773, 405, 548, 149, 940, 145, 114,  78, 727, 356,  54,\n",
       "       913,  39, 244,  36, 858, 963, 726,  77,  19, 607, 187, 586, 621,\n",
       "       264,  98, 884, 414, 733, 320, 971,  24, 205, 551, 547, 433, 678,\n",
       "       880,   5, 266, 404, 630, 939, 344, 618, 993, 406, 835, 991, 595,\n",
       "       265, 887, 298, 199, 204, 426, 998, 304, 165, 650, 460, 919, 600,\n",
       "       750,  47, 124, 534, 846, 943, 189, 281, 424, 374, 238, 355, 262,\n",
       "       393,  65, 196, 502, 237, 695, 954, 179,  27, 717, 728, 419, 714,\n",
       "       637, 933, 837, 584, 391, 602,  28, 982, 645, 994, 142, 366, 513,\n",
       "       748, 979, 447, 631, 397, 335, 185, 295, 505, 666, 445, 134, 193,\n",
       "       983, 746, 206,  75, 667, 793, 704, 315, 154, 904, 690, 925, 384,\n",
       "        25, 378, 659, 122, 658, 287, 805, 687,  40, 620, 140, 470, 853,\n",
       "       744, 351, 507, 885, 327, 215, 949, 382, 545, 240, 627, 127, 217,\n",
       "       821, 133, 486, 337, 362, 671, 455, 730, 861, 920, 497, 720,  62,\n",
       "       966, 221, 673, 804, 864, 418, 349, 541,  71, 859, 162, 799, 742,\n",
       "       957, 916, 209, 560, 267, 144, 959, 312, 428, 644, 646, 965, 296,\n",
       "       420, 354, 868, 624,   0, 960, 363, 785, 765, 663, 123, 535, 604,\n",
       "       332, 665, 554, 760, 182, 308, 660, 342, 401, 778, 247, 890, 161,\n",
       "        35, 707, 662, 519, 410, 411, 479, 117, 451, 438, 564, 763, 282,\n",
       "        86, 194, 311, 849, 115, 257, 924, 967, 285, 467, 339, 329, 693,\n",
       "       273, 222,  17, 361, 780, 614, 249, 494, 218, 290, 228, 801, 429,\n",
       "       815, 740, 596, 283, 415, 729,  84, 986,  50,  48, 997, 425, 102,\n",
       "       980,   8, 824, 907,  21, 867, 190, 903, 277, 360, 293, 364, 723,\n",
       "       734, 255,  96, 477, 376, 468, 510, 484, 700, 435, 668,  73, 400,\n",
       "       898, 501, 936, 188, 336,  22, 820, 475, 517, 421, 487, 851, 511,\n",
       "       444,  88, 191, 958,  66, 802, 365, 927, 902, 270, 686, 458, 109,\n",
       "       594,  56, 688,  32, 715, 195, 635, 539,  69, 492, 156, 896, 299,\n",
       "       759, 619, 599, 305, 754, 677, 570, 752, 198, 882, 786, 946, 956,\n",
       "       271, 610, 105, 233, 368, 248, 798, 343, 716, 276, 533, 346, 694,\n",
       "       211, 989, 469,  30, 399, 253, 917, 186,  53, 532, 340, 753, 359,\n",
       "       906, 603, 106, 768, 352, 932, 463, 292, 151, 894, 755, 879, 523,\n",
       "       806, 219, 328, 223, 567,  94, 647, 944, 396, 472, 875, 844,  16,\n",
       "       325, 175, 874, 245, 544, 407, 442, 636, 515,  60,  10, 452, 681,\n",
       "       181,  80, 275, 797, 148, 480, 128, 301, 628, 453, 736, 214, 792,\n",
       "       901, 654, 638,  70, 857, 500, 474, 810, 431, 608, 163,  57, 830,\n",
       "       842, 512, 978, 676, 909, 300, 609, 499, 860, 701,  93, 563, 372,\n",
       "       169, 937, 605, 623, 518, 330, 183, 709, 482, 739,  83,  92, 680,\n",
       "       170, 464, 675, 446, 522, 388, 256, 632, 891, 432, 192, 995, 263,\n",
       "       417, 488, 108, 809, 926, 674, 440, 422, 970, 314,  44, 392, 948,\n",
       "       490, 536, 353, 101,  64, 572, 573,  12,  74, 651, 201, 103, 777,\n",
       "       120, 643, 252,   9, 274,  41, 390, 910, 386, 509,  95, 823, 520,\n",
       "       977, 377, 542, 893, 987, 483, 945, 317, 812, 385, 153, 268, 527,\n",
       "       597, 402, 575, 964, 375, 737, 531, 769,  63, 870, 568, 319, 220,\n",
       "       641, 831,  85, 326, 434,  31,  20, 147, 817, 981,  18, 598, 992,\n",
       "       254, 443, 747, 915, 212, 897, 976, 508, 973,  51, 827, 583, 380,\n",
       "       171, 284, 322,  23, 682, 703, 942, 258, 757, 626, 819, 436, 562,\n",
       "       772, 379, 784, 272, 172, 794, 176, 289, 633, 473, 611, 670, 565,\n",
       "       341,  29, 713, 606, 928, 758, 395, 160, 601, 316, 841, 892, 138,\n",
       "       711, 862,  79, 104, 848, 866, 865, 803, 107, 251, 741, 900, 549,\n",
       "       886, 767, 370, 899, 721, 593,   7, 616, 762,  38, 280, 912, 941,\n",
       "       357, 132, 685, 307, 167, 543, 538, 745,  14, 923, 579, 358, 449,\n",
       "       230, 503, 242, 622, 450, 476, 648, 164, 984, 306, 807, 202, 236,\n",
       "       808, 566, 854,  42, 634, 657, 705, 216, 871, 506, 738, 580, 250,\n",
       "       800, 409, 310,  68,  81, 845, 416, 231,  11, 826, 969, 855, 578,\n",
       "       367, 286, 576, 985, 168, 413, 895, 324, 177,  49, 496, 863, 702,\n",
       "       178, 828, 559, 569, 173, 999, 203, 718, 683, 213, 318, 155, 180,\n",
       "       371, 119, 481, 323, 581, 347, 706, 146, 764,  45, 856, 546, 313,\n",
       "       691, 174, 839, 840, 732, 811, 465, 829, 291, 789, 836, 427, 550,\n",
       "       782,  26, 394, 553, 698, 350,  67,  99, 878, 639, 514, 227, 689,\n",
       "       118, 261, 766, 783, 931, 749,  34, 387, 136,  91, 403,  58,  52,\n",
       "       471, 552, 656, 625, 791, 131, 478, 143, 111, 239, 137, 587, 485,\n",
       "       241, 883, 294,  87, 493, 918, 582, 373, 129, 751, 655,   1, 873,\n",
       "       537, 524, 629,  37,  90, 947, 116, 838,  82, 235,  15,  72, 504,\n",
       "       495, 725, 929, 850, 697, 540, 345, 833, 889, 589, 243, 383, 953,\n",
       "       679, 588, 818, 692, 529, 125, 459, 381, 922, 952, 269, 743, 141,\n",
       "       672,  43,  46, 787,   4, 719, 652, 731, 776, 990, 558, 207])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`\n",
    "row_indices =np.random.permutation(1000)#numbers from 0 to 999 not in order\n",
    "row_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can create the three datasets using the `row_indices` ndarray to select the rows that will go into each dataset. Rememeber that the Training Set contains 60% of the data, the Cross Validation Set contains 20% of the data, and the Test Set contains 20% of the data. Each set requires just one line of code to create. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row_indices.shape is  (1000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"row_indices.shape is \", row_indices.shape)\n",
    "# Make any necessary calculations.\n",
    "# You can save your calculations into variables to use later.\n",
    "\n",
    "\n",
    "# Create a Training Set\n",
    "X_train = X_norm[row_indices[0:600], :]\n",
    "\n",
    "# Create a Cross Validation Set\n",
    "X_crossVal = X_norm[row_indices[600:800], :]\n",
    "\n",
    "# Create a Test Set\n",
    "X_test = X_norm[row_indices[800: ], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you performed the above calculations correctly, then `X_tain` should have 600 rows and 20 columns, `X_crossVal` should have 200 rows and 20 columns, and `X_test` should have 200 rows and 20 columns. You can verify this by filling the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X_train is :  (600, 20)\n",
      "The shape of X_crossVal is :  (200, 20)\n",
      "The shape of X_test is :  (200, 20)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of X_train\n",
    "print(\"The shape of X_train is : \", X_train.shape)\n",
    "\n",
    "# Print the shape of X_crossVal\n",
    "print(\"The shape of X_crossVal is : \", X_crossVal.shape)\n",
    "\n",
    "# Print the shape of X_test\n",
    "print(\"The shape of X_test is : \", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
